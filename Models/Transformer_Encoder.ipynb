{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C'est parti pour du faire Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datasets():\n",
    "    seed=1\n",
    "    batch_size = 32\n",
    "\n",
    "    raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "        '/Users/erwan/Programmes/Stage/Text_Classification/aclImdb/train',\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "        '/Users/erwan/Programmes/Stage/Text_Classification/aclImdb/train',\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "        '/Users/erwan/Programmes/Stage/Text_Classification/aclImdb/test',\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = raw_val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    test_ds = raw_test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle - Partie Encoder avec la Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_First_Encoder(tokenizer, hidden_dim):\n",
    "    \n",
    "    # Layers \n",
    "    embedding_layer = tf.keras.layers.Embedding(\n",
    "        input_dim=len(tokenizer.get_vocabulary()),\n",
    "        output_dim=hidden_dim,\n",
    "    )\n",
    "\n",
    "    query_layer = tf.keras.layers.Dense(hidden_dim)\n",
    "    key_layer = tf.keras.layers.Dense(hidden_dim)\n",
    "    value_layer = tf.keras.layers.Dense(hidden_dim)\n",
    "\n",
    "    norm_layer = tf.keras.layers.LayerNormalization()\n",
    "    linear_attention_layer = tf.keras.layers.Dense(hidden_dim)\n",
    "\n",
    "    linear_feed_forward_layer = tf.keras.layers.Dense(hidden_dim, activation='relu')\n",
    "    feed_forward_output_layer = tf.keras.layers.Dense(hidden_dim)\n",
    "\n",
    "    pooling_layer = tf.keras.layers.GlobalAveragePooling1D(name='pooling')\n",
    "    classification_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "    # Model \n",
    "    # Embedding (pas encore de positional encoding donc pas positional de embedding)\n",
    "    text_input = tf.keras.Input(shape=(), dtype=tf.string, name=\"input\")\n",
    "    tokenized_outputs = tokenizer(text_input)\n",
    "    embedded_outputs =  embedding_layer(tokenized_outputs)\n",
    "\n",
    "    # Attention zone\n",
    "    q_attention = query_layer(embedded_outputs)\n",
    "    k_attention = key_layer(embedded_outputs)\n",
    "    v_attention = value_layer(embedded_outputs)\n",
    "\n",
    "    attention_scores = tf.matmul(q_attention, k_attention, transpose_b=True)\n",
    "    attention_scores /= math.sqrt(hidden_dim)\n",
    "\n",
    "    attention_probs = tf.nn.softmax(attention_scores, axis=1)\n",
    "    z = tf.matmul(attention_probs, v_attention)\n",
    "\n",
    "    output = linear_attention_layer(z)\n",
    "    norm_output = norm_layer(embedded_outputs + output)\n",
    "\n",
    "    # Feed Forward \n",
    "    linear = linear_feed_forward_layer(norm_output)\n",
    "    ff_output = feed_forward_output_layer(linear)\n",
    "\n",
    "    # Classification\n",
    "    pooled_encoder_output = pooling_layer(ff_output)\n",
    "    output = classification_layer(pooled_encoder_output) \n",
    "\n",
    "\n",
    "    return tf.keras.Model(text_input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en oeuvre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = build_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "output_length = 100\n",
    "\n",
    "tokenizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_sequence_length=output_length\n",
    ")\n",
    "\n",
    "tokenizer.adapt(train_ds.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_encoder = my_First_Encoder(\n",
    "    tokenizer=tokenizer,\n",
    "    hidden_dim=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization_5 (TextVect  (None, 100)         0           ['input[0][0]']                  \n",
      " orization)                                                                                       \n",
      "                                                                                                  \n",
      " embedding_16 (Embedding)       (None, 100, 5)       50000       ['text_vectorization_5[3][0]']   \n",
      "                                                                                                  \n",
      " dense_80 (Dense)               (None, 100, 5)       30          ['embedding_16[0][0]']           \n",
      "                                                                                                  \n",
      " dense_81 (Dense)               (None, 100, 5)       30          ['embedding_16[0][0]']           \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_22 (TFOpLambd  (None, 100, 100)    0           ['dense_80[0][0]',               \n",
      " a)                                                               'dense_81[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.truediv_10 (TFOpLambda  (None, 100, 100)    0           ['tf.linalg.matmul_22[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.softmax_10 (TFOpLambda)  (None, 100, 100)     0           ['tf.math.truediv_10[0][0]']     \n",
      "                                                                                                  \n",
      " dense_82 (Dense)               (None, 100, 5)       30          ['embedding_16[0][0]']           \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_23 (TFOpLambd  (None, 100, 5)      0           ['tf.nn.softmax_10[0][0]',       \n",
      " a)                                                               'dense_82[0][0]']               \n",
      "                                                                                                  \n",
      " dense_83 (Dense)               (None, 100, 5)       30          ['tf.linalg.matmul_23[0][0]']    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 100, 5)      0           ['embedding_16[0][0]',           \n",
      " ambda)                                                           'dense_83[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 100, 5)      10          ['tf.__operators__.add_10[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_84 (Dense)               (None, 100, 5)       30          ['layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dense_85 (Dense)               (None, 100, 5)       30          ['dense_84[0][0]']               \n",
      "                                                                                                  \n",
      " pooling (GlobalAveragePooling1  (None, 5)           0           ['dense_85[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dense_86 (Dense)               (None, 1)            6           ['pooling[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 50,196\n",
      "Trainable params: 50,196\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]),\n",
       " TensorShape([1]),\n",
       " <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
       " array([b\"Kurosawa is a proved humanitarian. This movie is totally about people living in poverty. You will see nothing but angry in this movie. It makes you feel bad but still worth. All those who's too comfortable with materialization should spend 2.5 hours with this movie.\"],\n",
       "       dtype=object)>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_text, batch_label = next(iter(train_ds))\n",
    "f_text = batch_text[0]\n",
    "input = tf.expand_dims(f_text, -1) # Pour le passer en format (1, )\n",
    "\n",
    "f_text.shape, input.shape, input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_encoder(input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-4)\n",
    "metric = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "simple_encoder.compile(\n",
    "    loss=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    metrics=metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour TensorBoard\n",
    "nump_train = '001'\n",
    "logdir = \"logs/scalars/\" + nump_train\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 7s 9ms/step - loss: 0.6035 - binary_accuracy: 0.6028 - val_loss: 0.4596 - val_binary_accuracy: 0.7908\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.3760 - binary_accuracy: 0.8246 - val_loss: 0.4000 - val_binary_accuracy: 0.8216\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 5s 9ms/step - loss: 0.2946 - binary_accuracy: 0.8722 - val_loss: 0.4028 - val_binary_accuracy: 0.8286\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.2453 - binary_accuracy: 0.8978 - val_loss: 0.4276 - val_binary_accuracy: 0.8234\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.2084 - binary_accuracy: 0.9174 - val_loss: 0.4684 - val_binary_accuracy: 0.8190\n"
     ]
    }
   ],
   "source": [
    "# Entraînement \n",
    "epochs=5\n",
    "\n",
    "history = simple_encoder.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
